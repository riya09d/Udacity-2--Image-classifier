{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqI5P4-gDVF0",
        "outputId": "0873b24b-449a-4c57-e19f-a582de8165e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary packages\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "import json\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import time\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZZvuqXtlDXZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38bba26b-76ce-4730-b870-e721f58d8f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "#Define directories\n",
        "\n",
        "data_dir = 'flowers'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'\n",
        "\n",
        "# Define transforms for the training, validation, and testing sets\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "valid_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                       transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Load the datasets with ImageFolder\n",
        "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
        "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
        "\n",
        "# Define the dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)\n",
        "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32)\n",
        "\n",
        "print(\"Data loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eDP3Gc9QDYd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc785ec5-d90a-43fb-bb9b-42fb95e27f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category to name mapping loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Load the mapping from category label to category name\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)\n",
        "\n",
        "print(\"Category to name mapping loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fsy_1nOGDYat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c39277-9e88-4f81-ee84-3f5040dc29b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model built successfully.\n"
          ]
        }
      ],
      "source": [
        "# Load a pre-trained network\n",
        "model = models.vgg16_bn(pretrained=True)\n",
        "\n",
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Define a new, untrained feed-forward network as a classifier\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(25088, 4096)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('dropout', nn.Dropout(0.2)),\n",
        "                          ('fc2', nn.Linear(4096, 102)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "model.classifier = classifier\n",
        "\n",
        "print(\"Model built successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E1KTtAqDYZC"
      },
      "outputs": [],
      "source": [
        "# Set the device to GPU or CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 20\n",
        "steps = 0\n",
        "print_every = len(trainloader)  # This ensures the summary is printed once per epoch\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if steps % print_every == 0:\n",
        "            valid_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "              for inputs, labels in validloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model.forward(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "\n",
        "                    valid_loss += batch_loss.item()\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train loss: {running_loss/len(trainloader):.3f}.. \"\n",
        "                  f\"Validation loss: {valid_loss/len(validloader):.3f}.. \"\n",
        "                  f\"Validation accuracy: {accuracy/len(validloader) * 100:.2f}%\")\n",
        "            running_loss = 0\n",
        "            model.train()\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIxxtGv1DYVd"
      },
      "outputs": [],
      "source": [
        "# Test the network\n",
        "test_loss = 0\n",
        "accuracy = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Assuming 'testloader' is the name of your test dataloader\n",
        "    for inputs, labels in testloader:  # Replace 'dataloaders['test']' with 'testloader'\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "        logps = model.forward(inputs)\n",
        "        batch_loss = criterion(logps, labels)\n",
        "        test_loss += batch_loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        ps = torch.exp(logps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "print(f\"Test Loss: {test_loss/len(testloader):.3f}.. \"  # Also replace here\n",
        "      f\"Test Accuracy: {accuracy/len(testloader):.3f}\")  # And here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JoGIIMPDkZ3"
      },
      "outputs": [],
      "source": [
        "# Load the checkpoint\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = models.vgg16(pretrained=True)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.classifier = nn.Sequential(OrderedDict([\n",
        "        ('fc1', nn.Linear(25088, 4096)),\n",
        "        ('relu', nn.ReLU()),\n",
        "        ('dropout', nn.Dropout(0.5)),\n",
        "        ('fc2', nn.Linear(4096, 102)),\n",
        "        ('output', nn.LogSoftmax(dim=1))\n",
        "    ]))\n",
        "\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model.class_to_idx = checkpoint['class_to_idx']\n",
        "\n",
        "    return model\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiGghRTgDkWM"
      },
      "outputs": [],
      "source": [
        "def process_image(image_path):\n",
        "    pil_image = Image.open(image_path)\n",
        "    pil_image = pil_image.resize((256, 256))\n",
        "    left = (pil_image.width - 224) / 2\n",
        "    top = (pil_image.height - 224) / 2\n",
        "    right = (pil_image.width + 224) / 2\n",
        "    bottom = (pil_image.height + 224) / 2\n",
        "    pil_image = pil_image.crop((left, top, right, bottom))\n",
        "    np_image = np.array(pil_image) / 255\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    np_image = (np_image - mean) / std\n",
        "    np_image = np_image.transpose((2, 0, 1))\n",
        "    return torch.tensor(np_image).float()\n",
        "\n",
        "def predict(image_path, model, topk=5):\n",
        "    image = process_image(image_path)\n",
        "    image = image.unsqueeze(0)\n",
        "    model.eval()\n",
        "    # Move the image to the same device as the model\n",
        "    image = image.to(device)  # Add this line\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        ps = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        top_p, top_class = ps.topk(topk, dim=1)\n",
        "        idx_to_class = {v: k for k, v in model.class_to_idx.items()}\n",
        "        top_class = top_class.cpu().numpy()[0]\n",
        "        top_class = [idx_to_class[i] for i in top_class]\n",
        "    return top_p.cpu().numpy()[0], top_class\n",
        "\n",
        "print(\"Inference function for classification is ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_2OT2IrDkU9"
      },
      "outputs": [],
      "source": [
        "def imshow(image, ax=None, title=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    image = np.clip(image, 0, 1)\n",
        "    ax.imshow(image)\n",
        "    return ax\n",
        "\n",
        "import seaborn as sns\n",
        "def plot_solution(image_path, model):\n",
        "    plt.figure(figsize=(6,10))\n",
        "    ax = plt.subplot(2,1,1)\n",
        "    img = process_image(image_path)\n",
        "    # Assuming 'cat_to_name' maps class indices to flower names\n",
        "    flower_class = image_path.split('/')[-2]  # Extract the class from the path\n",
        "    title = cat_to_name.get(flower_class, 'Unknown Flower')  # Handle potential missing keys\n",
        "    imshow(img, ax, title=title)\n",
        "    probs, classes = predict(image_path, model)\n",
        "    class_names = [cat_to_name.get(item, 'Unknown Flower') for item in classes]  # Handle potential missing keys\n",
        "    plt.subplot(2,1,2)\n",
        "    sns.barplot(x=probs, y=class_names, color=sns.color_palette()[0])\n",
        "    plt.show()\n",
        "\n",
        "print(\"Prediction display function is ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model and set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(\"Model is loaded on the device:\", device)\n",
        "\n",
        "# Process and predict\n",
        "image_path = '/content/image_05658.jpg'\n",
        "img = process_image(image_path)\n",
        "print(\"Image processed successfully.\")\n",
        "\n",
        "probs, classes = predict(image_path, model)\n",
        "print(\"Predicted probabilities: \", probs)\n",
        "print(\"Predicted classes: \", classes)\n",
        "\n",
        "# Display the result\n",
        "plot_solution(image_path, model)\n",
        "print(\"Prediction display completed successfully.\")"
      ],
      "metadata": {
        "id": "E36LneDZFwyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JcmecXZQFwvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QZl5CtwfFwsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TrTXKnUOFwrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-_t0BODFwoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zf-JT8r0Fwm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}